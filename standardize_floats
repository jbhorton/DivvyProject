#Step 4 in the automated transformation sequence.
#Transform Float and Int transformations.

# Some of the rows must be coerced into FLOAT format. 
# Standardizing columns that should contain FLOAT data. 
# In the end I limited this to the coordinate data columns.
# Some cells were a few decimals long, others were high-precision coordinates with many decimals.
# I chose 5 decimals as a cutoff point to help limit the size of some of these columns.
# In the end I did not use it for analysis, but at first I thought I might try to make use of the GEOMETRY datatype in BigQuery SQL.

#Step summary
#Step 1 - Timestamp transformation
#Step 2 - Duration calculation in seconds
#Step 3 - Basic string calculation
#Step 4 - Float and Int transformations
#Step 5 - Specialized Rider-type transformation
#Step 6 - Specialized xxx_name transformations

#Objective summary

#def to_float('lat_end_station','lng_end_station','lat_start_station','lng_start_station')
# Processed by Step4.py and outputs to yyyy_clean4.csv
# Coerce each column to a 5-digit float, trimming more than 5 decimals and extending less with 0's.
# If possible overwrite the old columns. If not possible, write to new columns 'end_lat','end_long','start_lat','start_long' and drop the original columns.
# Empty cells and 'nan' cells to be formatted as SQL NULL value.

#def to_int('id_bike')
# Coerce all data to INT64 datatype. If this fails, coerce to a trimmed STRING datatype.
# If possible overwrite the old columns. If not possible, write to new column in the format 'old-column_standard' and drop the original columns.
# Empty cells and 'nan' cells to be formatted as SQL NULL value

#def to_rider_bday('rider_bday')
# Coerce all data to a four digit INT64 datatype if it fits within these parameters: (file-year - 90, to file-year - 5). Failed cases are written as NULL.
# If possible overwrite the old columns. If not possible, write to new columns 'user_bday' and drop the original columns.
# Empty cells and 'nan' cells to be formatted as SQL NULL value.

import pandas as pd
import os

def to_float(value):
    """Convert to float with 5 decimals, or None if invalid."""
    try:
        return round(float(value), 5) if pd.notna(value) else None
    except ValueError:
        return None

def to_int(value):
    """Convert to integer, or None if invalid."""
    try:
        return int(value) if pd.notna(value) else None
    except ValueError:
        return None

def process_file(file_path, output_path):
    """Process a single file for numeric transformations."""
    file_name = os.path.basename(file_path)
    print(f"Processing file: {file_name}")

    try:
        # Load in chunks to reduce memory usage
        chunk_size = 500000  # Adjust based on available memory
        processed_chunks = []

        for chunk in pd.read_csv(file_path, dtype=str, chunksize=chunk_size):
            print(f"Processing chunk of size {len(chunk)}...")

            # Apply transformations
            chunk['lat_start_station'] = chunk['lat_start_station'].apply(to_float)
            chunk['lng_start_station'] = chunk['lng_start_station'].apply(to_float)
            chunk['lat_end_station'] = chunk['lat_end_station'].apply(to_float)
            chunk['lng_end_station'] = chunk['lng_end_station'].apply(to_float)
            chunk['id_bike'] = chunk['id_bike'].apply(to_int)

            processed_chunks.append(chunk)

        # Concatenate all processed chunks
        result = pd.concat(processed_chunks)

        # Save to output file
        result.to_csv(output_path, index=False)
        print(f"File saved: {output_path}")

    except Exception as e:
        print(f"Error processing file {file_name}: {e}")

# Run the transformation
year = input("Enter year of file to be processed: ")

# File paths
input_file = f"input_filepath{year}_clean-3.csv"
output_file = f"output_filepath{year}_clean-4.csv"

# Run the file processing function
process_file(input_file, output_file)
